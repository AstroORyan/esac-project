The Hubble Legacy Archive (HLA) continues to be one of the largest data stores of astronomical imagery to date, with over 700,000 unprocessed images and roughly 95% of that being processed. Currently, a lot of these observations have been classified only by the meta data given to them upon observation. We aim to scan the HLA for interacting galaxies using the new Convolutional Neural Network (CNN) Zoobot. 

We focus on interacting galaxies as they are of fundamental importance to understanding galaxy formation and evolution. They drive not only matter assembly,
but likely a large part of the star formation history of the universe as well the formation of interesting galactic features and debris. A few examples being tidal tails and bridges, tidal dwarfs and rings. Using our CNN, we aim to create the largest consolidated sample of interacting galaxies since that of the Arp catalogue or the Atlas of Interacting Galaxies.

To do this, we will be using the CNN Zoobot; a newly released pre-trained model from the Galaxy Zoo collaboration. This CNN has already been trained to recognise galactic features using the Galaxy Zoo: DeCALS project. The model was found to be able to reproduce human classification in that project with an accuracy of up to 98%. However, we aim to take this and utilise transfer learning to apply this to HLA data and find the specific structure of interacting galaxies. Transfer learning (or finetuning) of the model is an excellent approach, as it only requires us to have a small training sample to get the model to recognise the specific features we are looking for. The training sample has been created from all previous Galaxy Zoo projects, with 
a total size of 7,569 interacting galaxies in our sample; far more than the recommended few hundred which would be required to conduct our transfer learning.

The final problem in this project is that of accessing the HLA. In order to conduct a thorough exploration of the HLA, many thousands of fits files would have to be downloaded and stored locally to be put through Zoobot. However, by using the new (and currently in Beta) DataLabs access to the entire HLA is provided. We have brought ourselves to the data rather than trying to bring the data to us. We can therefore mount the entire archive onto DataLabs and scan it as if it were within a local folder. This removes any latency issues which might crop up, and make this unfeasible. 

About me:
I am David Patrick O'Ryan, a 3rd PhD student at the University of Lancaster. This project was funded by the ESAC Archival Visitor Program (found here). To contact me, use email: d.oryan@lancaster.ac.uk.